---
title: Node.js爬虫获取漫威超级英雄电影海报
tags: 
- 漫威
- Node.js
- 爬虫
categories:
- Web技术
---



昨天去看了《复联3》的首映,当我提前15分钟进入影院的时候, 看到了粉丝们取票的长队, 顿时有一种跨年夜的感觉...
最近看了node爬虫的一些知识, 这里用node爬取一下漫威官网的电影海报!
![marvel](https://cdn.fangyuanxiaozhan.com/assets/1611570803039Jz0wtpRs.png)



```
// https://marvel.com/movies/all
const request = require('superagent')
const cheerio = require('cheerio')
const fs = require('fs-extra')
const path = require('path')

let url = 'https://marvel.com/movies/all'

// 获取图片url和图片名字
async function getUrlAndName(){
	// 用于存储返回值
	let imgAddrArray = []
	// 请求资源
	const res = await request.get(url)
	// 将获取的html, 转换为资源符$, 相当于python中的xpath语法的etree过程
	const $ = cheerio.load(res.text)
	// 定位资源位置, 将图片资源,和图片名字, 以数组方式, 返回给调用函数
	$('.row-item-image a').each(function(i, elem){
		let movieName = $(this).attr('href').split('/').pop()
		let imgAddr = $(this).find('img').attr('src')
		imgAddrArray.push([imgAddr, movieName])
	})
	return imgAddrArray
}
// 下载图片
async function download(imgAndName){
	// 拼接出, 当前资源的文件名
	let filename = imgAndName[1] + '.jpg'
	console.log("爬取海报:", filename);
	// 获取图片二进制数据
	const req = request.get(imgAndName[0]);
	// 保存图片
	await req.pipe(fs.createWriteStream(path.join(__dirname, 'images', filename))); 
}

// 创建文件夹, 控制整体流程
async function init(){
	let imgAddrArray = await getUrlAndName()
	// 创建文件夹
	try{
		await fs.mkdir(path.join(__dirname, 'images'));
	}
	catch(err){
		console.log("==>", err);
	}
	// 获取资源
	for (let imgAddr of imgAddrArray){
		await download(imgAddr);
	}
}

init()
```
![运行结果](https://cdn.fangyuanxiaozhan.com/assets/1611570759993501cPZxH.png)

## 小结:
直观感受, node爬虫并没有python好用, 而且由于浏览器的同源限制, 在浏览器端跑node爬虫也会有些麻烦；node爬虫的优势：理论上讲，node默认的异步玩法, 能达到python的多线程爬虫的效果.
写爬虫, **还是老老实实用Python吧!**